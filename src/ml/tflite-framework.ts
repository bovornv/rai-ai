// TFLite Training Framework for Rice Disease Classification
import { ModelMeta } from "../lib/ml-pipeline";
import fs from "fs";
import path from "path";

export interface TFLiteModelConfig {
  id: string;
  version: string;
  input_size: number;
  batch_size: number;
  epochs: number;
  learning_rate: number;
  weight_decay: number;
  architecture: "mobilenet_v2" | "efficientnet_b0" | "efficientnet_b1";
  quantization: {
    int8: boolean;
    float16: boolean;
    representative_samples: number;
  };
  fine_tuning: {
    frozen_epochs: number;
    fine_tune_epochs: number;
    unfreeze_layers: number;
  };
  augmentation: {
    horizontal_flip: boolean;
    rotation: number;
    brightness: number;
    contrast: number;
  };
}

export interface TFLiteDatasetConfig {
  data_root: string;
  crop: "rice" | "durian";
  classes: string[];
  train_split: number;
  val_split: number;
  test_split: number;
  min_samples_per_class: number;
  max_samples_per_class?: number;
}

export interface TFLiteArtifacts {
  savedmodel_path: string;
  int8_tflite_path: string;
  float16_tflite_path: string;
  labels_path: string;
  meta_path: string;
  config_path: string;
  metrics_path: string;
}

export class TFLiteModelManager {
  private modelsDir: string;
  private artifactsDir: string;

  constructor(modelsDir = "models", artifactsDir = "artifacts") {
    this.modelsDir = modelsDir;
    this.artifactsDir = artifactsDir;
    this.ensureDirectories();
  }

  private ensureDirectories() {
    [this.modelsDir, this.artifactsDir].forEach(dir => {
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
    });
  }

  // Create default TFLite model configuration
  createDefaultConfig(): TFLiteModelConfig {
    return {
      id: "rice_v1_tflite",
      version: "1.0.0",
      input_size: 224,
      batch_size: 32,
      epochs: 12,
      learning_rate: 3e-4,
      weight_decay: 1e-4,
      architecture: "mobilenet_v2",
      quantization: {
        int8: true,
        float16: true,
        representative_samples: 200
      },
      fine_tuning: {
        frozen_epochs: 12,
        fine_tune_epochs: 6,
        unfreeze_layers: 40
      },
      augmentation: {
        horizontal_flip: true,
        rotation: 0.05,
        brightness: 0.1,
        contrast: 0.1
      }
    };
  }

  // Create default dataset configuration
  createDefaultDatasetConfig(): TFLiteDatasetConfig {
    return {
      data_root: "./data/rice_dataset",
      crop: "rice",
      classes: [
        "rice_brown_spot",
        "rice_blast",
        "bacterial_leaf_blight",
        "healthy"
      ],
      train_split: 0.7,
      val_split: 0.15,
      test_split: 0.15,
      min_samples_per_class: 100,
      max_samples_per_class: 1000
    };
  }

  // Generate TensorFlow/Keras Colab notebook
  generateTrainingNotebook(config: TFLiteModelConfig, datasetConfig: TFLiteDatasetConfig): string {
    const notebook = `# Rice Disease Classification with TensorFlow Lite
# Generated by RaiAI TFLite Framework

#@title Install and imports
!pip -q install tensorflow==2.15.0 tensorflow-model-optimization==0.7.5 rich matplotlib scikit-learn

import os, json, time, math, random, pathlib, shutil
from rich.console import Console
console = Console()

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import classification_report, confusion_matrix

#@title Mount Google Drive & set paths
from google.colab import drive
drive.mount('/content/drive')

DATA_ROOT = "/content/drive/MyDrive/rice_dataset"
ARTIFACTS_DIR = "/content/rice_tf_artifacts"
os.makedirs(ARTIFACTS_DIR, exist_ok=True)

IMG_SIZE = ${config.input_size}
BATCH = ${config.batch_size}
EPOCHS = ${config.epochs}
SEED = 42

tf.random.set_seed(SEED)
np.random.seed(SEED)

console.log(f"Data root = {DATA_ROOT}")
console.log(f"Artifacts = {ARTIFACTS_DIR}")

#@title Build tf.data pipelines (with on-the-fly augmentation)

train_ds = tf.keras.utils.image_dataset_from_directory(
    os.path.join(DATA_ROOT, "train"),
    labels="inferred",
    label_mode="int",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH,
    shuffle=True,
    seed=SEED,
)
val_ds = tf.keras.utils.image_dataset_from_directory(
    os.path.join(DATA_ROOT, "val"),
    labels="inferred",
    label_mode="int",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH,
    shuffle=False,
)
test_ds = tf.keras.utils.image_dataset_from_directory(
    os.path.join(DATA_ROOT, "test"),
    labels="inferred",
    label_mode="int",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH,
    shuffle=False,
)

class_names = train_ds.class_names
num_classes = len(class_names)
console.log(f"Classes: {class_names}")

# Caching & prefetch for speed
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)
val_ds   = val_ds.cache().prefetch(AUTOTUNE)
test_ds  = test_ds.cache().prefetch(AUTOTUNE)

# Data augmentation block
data_augment = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(${config.augmentation.rotation}),
    layers.RandomBrightness(${config.augmentation.brightness}),
    layers.RandomContrast(${config.augmentation.contrast}),
], name="augment")

#@title Create & compile model (${config.architecture})
base = tf.keras.applications.${config.architecture.toUpperCase()}(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights="imagenet"
)
base.trainable = False  # freeze backbone first

inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = tf.keras.applications.${config.architecture}.preprocess_input(inputs)
x = data_augment(x)
x = base(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(num_classes, activation="softmax")(x)
model = keras.Model(inputs, outputs)

model.compile(
    optimizer=keras.optimizers.Adam(${config.learning_rate}),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

#@title Train (stage 1: frozen backbone)
cb = [
    keras.callbacks.ModelCheckpoint(
        os.path.join(ARTIFACTS_DIR, "best.h5"),
        monitor="val_accuracy", mode="max",
        save_best_only=True, save_weights_only=False
    ),
    keras.callbacks.EarlyStopping(monitor="val_accuracy", patience=4, restore_best_weights=True)
]

hist = model.fit(train_ds, validation_data=val_ds, epochs=${config.fine_tuning.frozen_epochs}, callbacks=cb)

# Fine-tune: unfreeze top ${config.architecture} blocks
base.trainable = True
for layer in base.layers[:-${config.fine_tuning.unfreeze_layers}]:  # unfreeze last ~${config.fine_tuning.unfreeze_layers} layers
    layer.trainable = False

model.compile(
    optimizer=keras.optimizers.Adam(${config.learning_rate * 0.1}),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

hist_ft = model.fit(train_ds, validation_data=val_ds, epochs=${config.fine_tuning.fine_tune_epochs}, callbacks=cb)

#@title Evaluate & show report
test_imgs, test_labels = [], []
for batch in test_ds:
    x, y = batch
    test_imgs.append(x)
    test_labels.append(y)
test_imgs = tf.concat(test_imgs, axis=0)
test_labels = tf.concat(test_labels, axis=0)

probs = model.predict(test_imgs, batch_size=BATCH)
preds = tf.argmax(probs, axis=1)

print(classification_report(test_labels.numpy(), preds.numpy(), target_names=class_names, digits=3))
print("Confusion matrix:\\n", confusion_matrix(test_labels.numpy(), preds.numpy()))

#@title Save SavedModel, labels.json, meta.json
SAVEDMODEL_DIR = os.path.join(ARTIFACTS_DIR, "rice_savedmodel")
if os.path.isdir(SAVEDMODEL_DIR): shutil.rmtree(SAVEDMODEL_DIR)
model.save(SAVEDMODEL_DIR, include_optimizer=False)

labels_path = os.path.join(ARTIFACTS_DIR, "labels.json")
with open(labels_path, "w", encoding="utf-8") as f:
    json.dump(class_names, f, ensure_ascii=False, indent=2)

meta = {
    "id": "${config.id}",
    "crop": "${datasetConfig.crop}",
    "task": "disease-classification",
    "version": "${config.version}",
    "input": {"width": IMG_SIZE, "height": IMG_SIZE, "channels": 3},
    "labels": class_names,
    "threshold_default": 0.75,
    "runtime": "tflite"
}
with open(os.path.join(ARTIFACTS_DIR, "meta.json"), "w", encoding="utf-8") as f:
    json.dump(meta, f, ensure_ascii=False, indent=2)

console.log(f"SavedModel at: {SAVEDMODEL_DIR}")
console.log(f"labels.json at: {labels_path}")

#@title Build representative dataset generator (uses train data)
REP_SAMPLES = ${config.quantization.representative_samples}  # more is better (100â€“500)
def representative_data_gen():
    count = 0
    for batch in tf.keras.utils.image_dataset_from_directory(
        os.path.join(DATA_ROOT, "train"),
        image_size=(IMG_SIZE, IMG_SIZE),
        batch_size=1,
        shuffle=True
    ).take(REP_SAMPLES):
        img = batch[0].numpy().astype(np.float32)
        # Must match the model's preprocessing
        img = tf.keras.applications.${config.architecture}.preprocess_input(img)
        yield [img]
        count += 1
        if count >= REP_SAMPLES:
            break

#@title TFLite conversion: int8 (full integer) + float16
${config.quantization.int8 ? `# INT8 (requires representative dataset)
converter = tf.lite.TFLiteConverter.from_saved_model(SAVEDMODEL_DIR)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type  = tf.int8
converter.inference_output_type = tf.int8
tflite_int8_path = os.path.join(ARTIFACTS_DIR, "${config.id}_int8.tflite")
tflite_int8 = converter.convert()
with open(tflite_int8_path, "wb") as f: f.write(tflite_int8)
console.log(f"INT8 model: {tflite_int8_path}  ({len(tflite_int8)/1024:.1f} KB)")` : ''}

${config.quantization.float16 ? `# FLOAT16 fallback (fast, easy)
converter_fp16 = tf.lite.TFLiteConverter.from_saved_model(SAVEDMODEL_DIR)
converter_fp16.optimizations = [tf.lite.Optimize.DEFAULT]
converter_fp16.target_spec.supported_types = [tf.float16]
tflite_fp16_path = os.path.join(ARTIFACTS_DIR, "${config.id}_fp16.tflite")
tflite_fp16 = converter_fp16.convert()
with open(tflite_fp16_path, "wb") as f: f.write(tflite_fp16)
console.log(f"FP16 model: {tflite_fp16_path}  ({len(tflite_fp16)/1024:.1f} KB)")` : ''}

#@title Sanity check TFLite inference (int8 or fp16)
${config.quantization.int8 ? `interpreter = tf.lite.Interpreter(model_path=tflite_int8_path)
interpreter.allocate_tensors()
input_details  = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input:", input_details)
print("Output:", output_details)

def tflite_predict(img_tensor_hwc_uint8):
    # Preprocess to ${config.architecture}, then quantize to int8 input scale
    x = img_tensor_hwc_uint8.astype("float32") / 255.0
    x = tf.keras.applications.${config.architecture}.preprocess_input(x)
    x = np.expand_dims(x, 0).astype("float32")

    # Quantization params
    scale, zero = input_details[0]["quantization"]
    x_q = (x / scale + zero).round().astype("int8")

    interpreter.set_tensor(input_details[0]["index"], x_q)
    interpreter.invoke()
    y_q = interpreter.get_tensor(output_details[0]["index"])  # int8
    y_scale, y_zero = output_details[0]["quantization"]
    y = (y_q.astype("float32") - y_zero) * y_scale  # dequantize to float
    probs = tf.nn.softmax(y[0]).numpy()
    idx = int(np.argmax(probs))
    return class_names[idx], float(probs[idx])

# Example (pick one test image path)
# from PIL import Image
# p = "/content/drive/MyDrive/rice_dataset/test/rice_blast/xxx.jpg"
# im = np.array(Image.open(p).convert("RGB").resize((IMG_SIZE, IMG_SIZE)))
# tflite_predict(im)` : ''}

#@title Zip artifacts for download
!cd /content && zip -r rice_tf_artifacts.zip rice_tf_artifacts >/dev/null
console.log("Artifacts:")
for p in os.listdir(ARTIFACTS_DIR):
    print(" -", p)
print("Zip ready at /content/rice_tf_artifacts.zip")
`;

    return notebook;
  }

  // Save configuration to file
  saveConfig(config: TFLiteModelConfig, filename?: string): string {
    const configPath = path.join(this.artifactsDir, filename || `${config.id}_config.json`);
    fs.writeFileSync(configPath, JSON.stringify(config, null, 2));
    return configPath;
  }

  // Load configuration from file
  loadConfig(configPath: string): TFLiteModelConfig {
    const configData = fs.readFileSync(configPath, 'utf8');
    return JSON.parse(configData);
  }

  // Generate model metadata for registry
  generateModelMeta(config: TFLiteModelConfig, labels: string[]): ModelMeta {
    return {
      id: config.id,
      crop: "rice",
      task: "disease-classification",
      version: config.version,
      input: { 
        width: config.input_size, 
        height: config.input_size, 
        channels: 3 
      },
      labels: labels,
      threshold_default: 0.75,
      runtime: "tflite",
      path: path.join(this.modelsDir, `${config.id}_int8.tflite`)
    };
  }

  // Validate TFLite artifacts
  validateArtifacts(artifacts: TFLiteArtifacts): { valid: boolean; errors: string[] } {
    const errors: string[] = [];
    
    if (!fs.existsSync(artifacts.savedmodel_path)) {
      errors.push(`SavedModel not found: ${artifacts.savedmodel_path}`);
    }
    
    if (!fs.existsSync(artifacts.labels_path)) {
      errors.push(`Labels file not found: ${artifacts.labels_path}`);
    }
    
    if (!fs.existsSync(artifacts.meta_path)) {
      errors.push(`Metadata file not found: ${artifacts.meta_path}`);
    }
    
    if (!fs.existsSync(artifacts.int8_tflite_path)) {
      errors.push(`INT8 TFLite model not found: ${artifacts.int8_tflite_path}`);
    }

    if (!fs.existsSync(artifacts.float16_tflite_path)) {
      errors.push(`Float16 TFLite model not found: ${artifacts.float16_tflite_path}`);
    }

    return {
      valid: errors.length === 0,
      errors
    };
  }

  // Deploy TFLite model artifacts to production
  deployModel(artifacts: TFLiteArtifacts): boolean {
    try {
      const validation = this.validateArtifacts(artifacts);
      if (!validation.valid) {
        console.error("TFLite model validation failed:", validation.errors);
        return false;
      }

      // Copy TFLite models to models directory
      const int8Dest = path.join(this.modelsDir, path.basename(artifacts.int8_tflite_path));
      const float16Dest = path.join(this.modelsDir, path.basename(artifacts.float16_tflite_path));
      
      fs.copyFileSync(artifacts.int8_tflite_path, int8Dest);
      fs.copyFileSync(artifacts.float16_tflite_path, float16Dest);
      
      // Copy labels and metadata
      const labelsDest = path.join(this.modelsDir, path.basename(artifacts.labels_path));
      const metaDest = path.join(this.modelsDir, path.basename(artifacts.meta_path));
      
      fs.copyFileSync(artifacts.labels_path, labelsDest);
      fs.copyFileSync(artifacts.meta_path, metaDest);

      console.log(`TFLite model deployed successfully to ${this.modelsDir}`);
      return true;
    } catch (error) {
      console.error("TFLite model deployment failed:", error);
      return false;
    }
  }

  // Generate TFLite model report
  generateModelReport(config: TFLiteModelConfig, metrics: any[]): string {
    return `
# TFLite Model Report: ${config.id}

## Configuration
- Architecture: ${config.architecture}
- Input Size: ${config.input_size}x${config.input_size}
- Quantization: INT8 + Float16
- Frozen Epochs: ${config.fine_tuning.frozen_epochs}
- Fine-tune Epochs: ${config.fine_tuning.fine_tune_epochs}

## Model Artifacts
- INT8 TFLite: ${config.id}_int8.tflite (optimized for mobile)
- Float16 TFLite: ${config.id}_fp16.tflite (fallback)
- SavedModel: rice_savedmodel/ (for re-export)
- Labels: labels.json
- Metadata: meta.json

## Mobile Deployment
- **INT8 Model**: Best for low-end Android devices
- **Float16 Model**: Fallback for devices without INT8 support
- **Preprocessing**: MobileNetV2 normalization
- **Input**: 224x224x3 RGB images
- **Output**: Softmax probabilities

## Next Steps
1. Deploy INT8 model to mobile app
2. Use Float16 as fallback
3. Test on target devices
4. Monitor performance in production
`;
  }
}

// Export singleton instance
export const tfliteModelManager = new TFLiteModelManager();
